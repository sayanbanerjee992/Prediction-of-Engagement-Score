{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Engagement Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABC is an online content sharing platform that enables users to create, upload and share the content in the form of videos. It includes videos from different genres like entertainment, education, sports, technology and so on. The maximum duration of video is 10 minutes.\n",
    "Users can like, comment and share the videos on the platform. \n",
    "Based on the user’s interaction with the videos, engagement score is assigned to the video with respect to each user. Engagement score defines how engaging the content of the video is. \n",
    "Understanding the engagement score of the video improves the user’s interaction with the platform. It defines the type of content that is appealing to the user and engages the larger audience.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the POC, the following will be the final method:\n",
    "\n",
    "1. Train SVD on a subset of the data. \n",
    "2. Get the initial predictions.\n",
    "3. Calculate the error\n",
    "4. Train a regressor model on the error\n",
    "5. Calculate the final prediction by adding the error estimate and the initial prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Questions to Answer**\n",
    "\n",
    "1. On what percentage of the total records should the SVD be trained? \n",
    "2. What should be the hyperparameters of SVD and the regressors? SVD is already answered, from the POC.\n",
    "3. While training the regressors, should we include category id? If yes, which encoder should be used?\n",
    "4. Can we use weighted sums to get the final prediction, rather than the simple sum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANY UNUSED IMPORTS. CLEAN UP\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import r2_score, accuracy_score, mean_squared_error\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import CatBoostEncoder\n",
    "\n",
    "from surprise.prediction_algorithms import SVD as SVD_sp\n",
    "from surprise import Reader as Reader_sp\n",
    "from surprise import Dataset as Dataset_sp\n",
    "from surprise.model_selection import train_test_split as train_test_split_sp\n",
    "from surprise.accuracy import rmse as rmse_sp\n",
    "from surprise.model_selection import GridSearchCV as GridSearchCV_sp\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_0OECtn8.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of the data on which the SVD is trained. This means that the regressors will be trained on 1 - svd_subset\n",
    "svd_subset = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset into one that works with Surprise\n",
    "df_surprise = df[['user_id', 'video_id', 'engagement_score']].copy()\n",
    "df_surprise = df_surprise.sample(frac=1).reset_index(drop=True)\n",
    "reader = Reader_sp(rating_scale=(0, 5))\n",
    "df_surprise = Dataset_sp.load_from_df(df_surprise, reader=reader)\n",
    "train_sp, test_sp = train_test_split_sp(df_surprise, train_size=svd_subset, test_size=1-svd_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fdb3d08d7c0>"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on the train set\n",
    "svd = SVD_sp(n_factors=100, n_epochs=500, lr_all=0.05)\n",
    "svd.fit(train_sp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the initial estimates for the test set\n",
    "preds_sp = svd.test(test_sp)\n",
    "y_pred = list(map(lambda x: x.est, preds_sp))\n",
    "y_true = list(map(lambda x: x.r_ui, preds_sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4655336895459784"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Prediction\n",
    "\n",
    "We train the regressor model on the test set created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out only those records from the source dataframe that are in test_sp\n",
    "test_sp = pd.DataFrame(test_sp)\n",
    "test_sp.columns = ['user_id', 'video_id', 'engagement_score']\n",
    "df_v2 = df.merge(test_sp, on=['user_id', 'video_id', 'engagement_score'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in the initial estimates and the errorto the new train set\n",
    "df_v2['initial_estimate'] = y_pred\n",
    "df_v2['error'] = df_v2['initial_estimate'] - df_v2['engagement_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We **subtract** the error from the initial estimate to get the correct value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop row id and engagement score, cannot use those\n",
    "df_v2 = df_v2.drop(['row_id', 'engagement_score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy columns for gender and profession\n",
    "df_v2 = pd.get_dummies(df_v2, columns=['gender', 'profession'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGB on df_v2\n",
    "X = df_v2.drop(['error'], axis=1)\n",
    "Y = df_v2['error'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decided against using the category id in the training set, as no encoding method was working well. *Perhaps I need to study encoding methods in more detail*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encode the other categorical variables\n",
    "# cbe = CatBoostEncoder(cols=['category_id', 'video_id', 'user_id'])\n",
    "# cbe.fit(X, Y)\n",
    "# X = cbe.transform(X)\n",
    "\n",
    "# Drop categorical variables\n",
    "X = X.drop(['user_id', 'category_id', 'video_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a Few Models** - Finally going with Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=500)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Train RF\n",
    "# rf = RandomForestRegressor(n_estimators=500)\n",
    "# rf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Train XGBoost\n",
    "# xgb = XGBRegressor(n_estimators = 100)\n",
    "# xgb.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use some basic error estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression(fit_intercept=True)\n",
    "lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join All\n",
    "\n",
    "Run the entire pipeline on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_1zqHu22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_predictions = df_test.drop(['row_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_predictions = pd.get_dummies(df_test_predictions, columns=['gender', 'profession'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the predictions with SVD\n",
    "initial_predictions = [svd.predict(\n",
    "                            df_test_predictions.loc[i, 'user_id'], \n",
    "                            df_test_predictions.loc[i, 'video_id']\n",
    "                                    ).est for i in range(len(df_test_predictions))]\n",
    "\n",
    "df_test_predictions['initial_estimate'] = initial_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the error estimate using the regressor.\n",
    "df_test_predictions = df_test_predictions.drop(['user_id', 'category_id', 'video_id'], axis=1)\n",
    "error_predictions = lr.predict(df_test_predictions)\n",
    "df_test_predictions['error_estimate'] = error_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final engagement score is the weighted sum of the initial estimate and the error estimate. The weight is `1-svd_subset`. \n",
    "\n",
    "Currently, the svd_subset is set at 0.95, so the error gets only 5% weightage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_predictions['engagement_score'] = df_test_predictions['initial_estimate'] - ((1-svd_subset)*(df_test_predictions['error_estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['engagement_score'] = df_test_predictions['engagement_score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case the engagement score crosses 5 or drops below 0, get them back to the threshold.\n",
    "df_test.loc[df_test['engagement_score']>5, 'engagement_score'] = 5\n",
    "df_test.loc[df_test['engagement_score']<0, 'engagement_score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['row_id', 'engagement_score']].to_csv('final_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
